---
title: "basic_sr_demo"
author: "Papoula Petri-Romão"
date: "2024-08-29"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: true
    toc_depth: 3
    number_sections: false
    theme: lumen
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)

# This is the "setup" chunk. It is best practice to specify all the packages you will use here.

# the pacman package allows you to manage packages easily, since it will install any packages you don't have and simply load those packages you do have
require(pacman)

# now load packages
p_load(
  tidyverse, # for data management
  lme4, # for multilevel modelling
  ggcorrplot, # for plotting correlations
  ggsignif
)
```


We are using the publically available [Dynacore-L dataset available on OSF](https://osf.io/d6wgr/). The main analyses of this dataset were published by [Boegemann et al. in 2022](https://mental.jmir.org/2023/1/e46518). The calculations here will slightly differ from these main analyses for the purpose of exemplifying SR calculation. 

We have processed the data set to be a bit easier to work with for the purpose of this workshop, but the data remains the same. 

You will find the ressymp_workshop data on our github. 

```{r loaddata}

ds <- read_csv("ressymp_workshop.csv")

```

# Basic SR score

The "Stressor Reactivity" is the reaction as expressed in mental health problems (P) to stressors (E). Therefore you need to identify the stressor exposure measures (E) and measures of mental health problems/symptoms in your dataset (P). 

## 1 Identify your E and P 

In Dynacore-L we have two types of stressors, Corona-related stressors and General stressors. 

* CE : Corona-related stressors, 29 items; 0-5, 0= did not happen. 
* GE : General stressors, 11 items; 0-5, 0= did not happen. 

CE_30 and GE_12 are open questions and are not used for this scoring. 

      Task 1a: Find stressor items in the dataset and look at this subset of variables. Check that the range of the items is as expected. 
      
```{r solution_identify_E}

# there are many acceptable solutions, this is the dplyr way
ds %>% 
  dplyr::select(
    starts_with(
      c("GE_", "CE_")
      )
    ) %>% 
  # head returns the first 10 columns of the subset
  head

# summary return min, max, quartiles, median and mean
ds %>% 
  dplyr::select(starts_with(c("GE_", "CE_"))) %>% 
  summary()

```

As P we have the GHQ (CM in the dataset). 

CM : 0-3, where 0 is did not happen.

      Task 1b: Find mental health items in the dataset and look at this subset of variables. Check that the range of the items is expected. 
      
```{r solution_identify_P}

# there are many acceptable solutions, this is the dplyr way
ds %>% 
  dplyr::select(
    starts_with("CM")
  ) %>% 
  # head returns the first 10 columns of the subset
  head

ds %>% 
  dplyr::select(
    starts_with("CM")
  ) %>% 
  # summary returns min, max, quartiles, median and mean
  summary()

```


### 1.1 building sum scores

#### 1.1.1 P

Score your P according to the manual. 
For GHQ this is a sum score of all items. 

      Task 1.1.1a: Calculate the sum score of GHQ (P)
      
```{r solution_p_sumscore}

ds <- ds %>% 
  # mutate allows us to create a new variable
  dplyr::mutate(
    # we name this new variable P & calculate the Sum per row
    P=base::rowSums(
      # with across we specify what columns are summed
      across(c(CM_01:CM_12)),
      # here we specify that if there is an NA value it is removed
      na.rm = T)
                )

```


#### 1.1.2 E

Dependent on your data set you might have different considerations on how you will build your E sum score.

If you have different type of stressors within the same data set, for example, life events and daily hassles, or general and pandemic stressors, you will in most cases want to built separate sum scores for each type of stressor first. 

      Task 1.1.2a: Create two sum scores, one for the general stressors (Eg), one for the corona-related stressors (Es). 
      
```{r solutions_ec_eg}

ds <- ds %>% 
  # mutate allows us to create a new variable
  dplyr::mutate(
    # we name this new variable Eg & calculate the Sum per row
    Eg=base::rowSums(
      # with across we specify what columns are summed
      across(c(GE_01:GE_11)),
      # here we specify that if there is an NA value it is removed
      na.rm = T),
    # now we calculate a separate E for the pandemic stressors
    Es=base::rowSums(
      # with across we specify what columns are summed
      across(c(CE_01:CE_29)),
      # here we specify that if there is an NA value it is removed
      na.rm = T)
                )

```


#### 1.1.3 to scale or not to scale?

Now the question is how could one combine the E scores. Usually, you want to built the SR score based on the most information available, meaning all types of available stressors. There are two options: 

1. you could sum all items. This works when all stressors are measured or coded the same way and on the same scale(for example all of them indicate occurrence). This would mean that if the type of stressors are not equally represented, the one type for which there are more items will be weighted more. In our example, there are more CE (29 items) then general stressors (11 items). 
2. you could create a mean of the scaled sum scores. this would allow both type of stressors to be equally weighted. This is the approach we have used in MARP and LORA which is described in the [FRESHMO paper](https://www.frontiersin.org/articles/10.3389/fpsyg.2021.710493). 

      Task 1.1.3: create a scaled combined E score (E_scaled) 

```{r solution_scaled_E}

ds <- ds  %>% 
  ungroup %>% 
  # here we are scaling across all time points and all participants
  mutate(Eg_scaled= scale(Eg),
         Es_scaled=scale(Es)) %>% 
dplyr::group_by(subject.ID) %>% 
  # because we are creating the mean by rows and not by column
  rowwise() %>% 
  dplyr::mutate(E_scaled=mean(c(Eg_scaled,Es_scaled),na.rm = T))%>% 
  # this is important to make revert the rowwise operator
  ungroup %>%  
  dplyr::group_by(subject.ID) 
```

      
#### 1.1.4 per timepoint/over time periods

SR is expected to be quite stable and change over longer periods of times. That is a sudden or short change in SR is usually not indicative of less resilient outcomes, rather it is the SR over longer time periods that is more informative on the resilience of participants. 
Consequently, in longitudinal studies we are often interested in longer time periods rather than single time points. For example in the longitudinal samples MARP and LORA we look at period of 9 months to ca. 3.5 years [see Petri-Romão et al.](https://osf.io/dgx4k). 
For this purpose we create the mean stressor exposure and mean P in the time period of interest. 

      Task 1.1.4a: Create mean E scores (Eg_t1.t6, Es_t1.t6) across all timepoints
      
```{r solution_Et1_t6}

ds <- ds %>% 
  group_by(subject.ID) %>% 
  mutate(
    Eg_t1.t6 = base::mean(
      # we mean the already calculated sum score
      Eg,
      # here we specify that if there is an NA value it is removed
      na.rm = T),
    # now we calculate a separate E for the pandemic stressors
    Es_t1.t6 =base::mean(
      Es,
      # here we specify that if there is an NA value it is removed
      na.rm = T)
  ) 

```

      Task 1.1.4b: Create mean P scores (P_t1.t6) across all timepoints
      
```{r solution_Pt1_t6}

ds <- ds %>% 
  group_by(subject.ID) %>% 
  mutate(
    P_t1.t6 = base::mean(
      # we mean the already calculated sum score
      P,
      # here we specify that if there is an NA value it is removed
      na.rm = T)
  ) 

```

In the case of the combined E score the order of operations is as follows

1. create mean sum scores for each time period (separately for Eg, Es)
2. scale each separate sum score. This means we are scaling over the time period of interest
3. create combined mean score of the scaled scores

      Task 1.1.4c: Create combined E scores over the whole time period E_t1.t6, E_t1.t6_scaled
      
```{r solution_Et1_t6_scaled}

ds <- ds %>% 
  group_by(subject.ID) %>% 
  # first we create a mean of the simple combined sum score
  mutate(E_t1.t6 = base::mean(E, na.rm=TRUE)) %>% 
    ungroup() %>% 
  # now we create an equally weighted E mean score over t1 to t6
  mutate(
    Eg_t1.t6_scaled = scale(
      # we mean the already calculated sum score (see previous chunk)
      Eg_t1.t6),
    # now we calculate a separate E for the pandemic stressors
    Es_t1.t6_scaled = scale(
      Es_t1.t6)
  ) %>% 
  # now we create a combined mean score
  group_by(subject.ID) %>% 
  mutate(
    E_t1.t6_scaled = base::mean(c(Eg_t1.t6_scaled, Es_t1.t6_scaled), na.rm=TRUE)
  )

```

### 1.2 first look into E and P

First we check that our scores are reasonable. Plotting and summarising the scores makes sense to check that you have done everything correctly and give you a sense if there are outliers. We will not look into the treatment of outliers now, but as good practice you should get used to plotting and checking your data.

      Task 1.2a: Describe the scores
      Generate descriptive statistics of the scores you build to check their quality. (e.g. mean, median, min, max)
      EXTRA: plot the scores. (e.g. scatter, histogram, boxplot...)
      
      Task 1.2b: Interpret your results
      * did you do everything correctly? or are there strange scores, eg. outside of the possible range?
      * do you think there are outliers?

```{r solution_describeEP}
# skimr::skim offers a quick look into each variable
ds %>% 
  ungroup() %>% 
  # select the variables you want to look at 
  select(E,E_scaled, Es, Eg, E_t1.t6, Es_t1.t6, Eg_t1.t6,E_t1.t6_scaled, Es_t1.t6_scaled, Eg_t1.t6_scaled, P) %>% 
  skimr::skim()

## Plotting ###

ds %>% 
  group_by(subject.ID) %>% 
  select(subject.ID,E,E_scaled, Es, Eg, E_t1.t6, Es_t1.t6, Eg_t1.t6,E_t1.t6_scaled, Es_t1.t6_scaled, Eg_t1.t6_scaled, P) %>% 
  # we need to reformat the dataset for easier plotting in ggplot, but you can also skip this if you want to plot them separately
  pivot_longer(-subject.ID) %>% 
  # plotting happens here
  ggplot(aes(y=value))+
  # we choose the kind of plot
  geom_boxplot()+
  # this creates separate plot for each variable. scales=free adjusts the axes for each plot individually
  facet_wrap(~name, scales = "free")


```



### 1.3 Choosing E 

We want to choose an E score based on a robust (that is high and interpretable) relationship with P. 

      Task 1.3a: Calculate the correlations between E an P 
      Calculate them between all scores or just one, depending on your knowledge of coding.
      EXTRA: plot the correlation matrix for easy interpretation.

      Task 1.3b: Interpret the scores
      * which E score has the highest correlation with P?
      * what do the separate E scores' correlations tell you about their influence on P? (is Eg or Es more important)
      * does the scaling of different E types before summation have an impact on the relationship?
      * what could be a reason to choose separate scores rather than combined scores?
      * which E score would you use?



```{r solution_choosingE}
# here we just calculate all the different correlations
ds %>%  
  ungroup() %>% 
  select(E,E_scaled, Es, Eg, P) %>% 
  cor(., use="pairwise.complete.obs")

# here we plot the correlations with ggcorrplot
ds %>%  
  ungroup() %>% 
  select(E,E_scaled, Es, Eg, P) %>% 
  cor(., use="pairwise.complete.obs")%>%  
  ggcorrplot::ggcorrplot(
                          show.legend = TRUE, type="lower", method = "circle", lab=TRUE,
                          ggtheme = ggplot2::theme_classic)

# here we calculate the correlations of the average E and P in t1-t6
ds %>%  
  ungroup() %>% 
  select(E_t1.t6, Es_t1.t6, Eg_t1.t6,E_t1.t6_scaled, P_t1.t6) %>% 
  cor(., use="pairwise.complete.obs")

# here we plot again
ds %>%  
  ungroup() %>% 
  select(E_t1.t6, Es_t1.t6, Eg_t1.t6,E_t1.t6_scaled, P_t1.t6)%>%  
  stats::cor(., use = "pairwise.complete.obs") %>%  
  ggcorrplot::ggcorrplot(
                          show.legend = TRUE, type="lower", method = "circle", lab=TRUE,
                          ggtheme = ggplot2::theme_classic)
```

Solution:

* which E score has the highest correlation with P?
_E_scaled has the highest relationship with P. E_t1.t6_scaled has the highest correlation with P_t1.t6_

* what do the separate E scores' correlations tell you about their influence on P? (is Eg or Es more important)
_Es has lower relationship with P than Eg. But Es has a higher correlation with E, which makes sense, since there are more items that go into E._ 

* does the scaling of different E types before summation have an impact on the relationship?
_Eg and Es are equally correlated with E_scaled, which makes sense, since they are now equally weighted. The correlation is actually higher when we create a scaled E score_

* what could be a reason to choose separate scores rather than combined scores?
_in specific times, such as the pandemic, we might have hypotheses regarding the differential impact of distinct type of stressors on P_

* which E score would you use?
_for simplicity we will proceed with E and E_t1.t6 without scaling, this is also more closely aligned with the analyses in Dynacore-L_

## 2 Model for normative stressor reactivity

The basis of the SR score for each individual is the presumed normative relationship between E and P, that is the normative reactivity in terms of mental health problems to the exposure of stressors. 
In this part we will calculate the normative E~P line. 

Usual considerations

* use all available data in completed studies
* pre-define acceptable amount of incomplete assessments (e.g. participants must have completed 2/3 assessments)
* you will usually need multiple time points

### 2.1 multilevel vs simple modelling

In cross-sectional samples you will always have to use simple modelling. 
However, in longitudinal samples you can either use multilevel modelling or choose to average over all time points to use simple modelling. The resulting SR scores usually are highly correlated and it is mostly a conceptual distinction. 

In studies were data collection is ongoing studies we have so far used the second appraoch, that is averaging over time points and building simple models. See the FRESHMO paper [Kalisch et al.](https://www.frontiersin.org/articles/10.3389/fpsyg.2021.710493)
For further details refer to the advanced sr script, where the use of a "reference time period" is discussed. 

In studies where you compare different time points, for example intervention studies, we have chosen multilevel modelling (see [Petri-Romão et al. (2024)](https://osf.io/dgx4k)). In completed studies we have also used multilevel modelling, see [Boegemann et al. in 2022](https://mental.jmir.org/2023/1/e46518)

#### 2.1.1 simple modelling

In a cross-sectional study or if computing the normative EP line in a single timepoint you will always use a simple model. 

For this you will define your P of interest (your predicted variable y) and your E in the corresponding time period (your x). 

For the sake of this example we will look at the average mental health problems over all assessments (P_t1.t6) and average stressor exposure in that time period (E_t1.t6). 

      Task 2.1.1a Build a simple linear model predicting P with E. Save the summary output in an object. 


```{r solution_simplemodel}


EP_norm <- ds %>% 
  # we first specify the model
  lm(P_t1.t6~E_t1.t6, data=.) %>% 
  # then we save the summary in an object we name EP_norm
  summary()

EP_norm
  

```


#### 2.1.2 multilevel modelling

Multilevel modelling allows us to build models with repeated measures of E and P. 
It has been used in Dynacore-L and the RESPOND-RCT intervention study. 
It is particularly useful when the study is completed and if averaging would obscure the effect of interest. 

Note that in this example the mixed model results in an (almost / near) singular fit, probably because the inclusion of random slopes overfits the data. However, for SR calculation, we do not interpret the overall model fit and only use the fixed effects.

      Task 2.1.2 Build a multilevel model with the lmer function, specifying a random intercept for each subject. Save the output summary in an object. 
      
```{r solution_multilevel}

EP_multi <- ds %>% 
  # to create a multilevel model we must specify that there are repeated measurements for each participant. For this we group the dataframe
  group_by(subject.ID) %>% 
  # specify a model with a random effect for each subject
  lme4::lmer(scale(P)~scale(E)+ (1+scale(E)|subject.ID),data=.) %>% 
  summary()

EP_multi
  
```


### 2.2 linear vs quadratic

As specified in the FRESHMO paper [Kalisch et al.](https://www.frontiersin.org/articles/10.3389/fpsyg.2021.710493), the relationship between E and P is mostly linear, but could also be quadratic. 
It is best practice to test whether the linear or quadratic relationship is the best fit. 

      Task 2.2 Test wether the E/P relationship is best described with a linear or quadratic model. This is best done with an anova. Interpret the result. You can do so with the simple or multilevel models. 

```{r solution_linquad}
# when comparing models it's important that you build them with the same syntax, so that the anova understands that they are comparable

# building the linear model 
EP_lin <- ds%>%
  group_by(subject.ID) %>%
lm(P_t1.t6~poly(E_t1.t6,1, raw =TRUE),data=.) 

# building the quadratic model
EP_quad <- ds%>%
  group_by(subject.ID) %>%
lm(P_t1.t6~poly(E_t1.t6,2, raw =TRUE),data=.) 

# run an anova comparing the model
anova(EP_lin, EP_quad,test="Chisq")
# The anova comes back with a stat. signif. difference between the models, saying that the quadratic model is stat. better than the linear one. 


#### multilevel ###

# building the linear model 
EP_lin_multi <- ds%>%
  group_by(subject.ID) %>%
  lme4::lmer(scale(P)~poly(scale(E),1, raw = TRUE)+(1+scale(E)|subject.ID),data=.)

# building the quadratic model
EP_quad_multi <- ds%>%
  group_by(subject.ID) %>%
lme4::lmer(scale(P)~poly(scale(E),2, raw = TRUE)+(1+scale(E)|subject.ID),data=.)

# run an anova comparing the model
anova(EP_lin_multi, EP_quad_multi,test="Chisq")
# The anova says that there is no stat. signif. difference between the models
```

#### 2.2.1 plot 

To further understand the relationship it can also be useful to plot the E/P lines. Here it would be possible to identify outliers as well (the treatment of outliers is explained in the next advanced part of the script)

        Task 2.2.1 Plot the E/P relationship twice. Once with fitting a linear line and once fitting a quadratic line onto the squatterplot. 
```{r solution_plotline}

# plot a linear relationship
plotlin <-  ds %>% 
  ggplot(aes(x = E, y = P)) +
  geom_point() +
  labs(x="E", y="P") +
  # adding an EP line based on linear modelling
  geom_smooth(method = "lm")+
  # this just makes it prettier
  theme_classic()

plotlin

# plot a quadratic relationship
plotquad <- ds %>% 
  ggplot(aes(x = E, y = P)) +
  geom_point() +
  labs(x="E", y="P") +
  # adding an EP line based on a quadratic relationship
  geom_smooth(formula = y ~ poly(x, 2, raw=TRUE))+
  theme_classic()

plotquad
```



### 2.3 explained variance

As a way of testing the quality of your model you can analyse the explained variance of the model

      Task 2.3 Calculate the R2 of the linear and quadratic model we have just compared. 

```{r solution_rsquared}
# R squared of the linear model previously calculated
summary(EP_lin)$adj.r.squared

# R squared of the quadratic model previously calculated
summary(EP_quad)$adj.r.squared
```


### 2.4 decide on model

Things to consider

*Are you interested in an average time period or single timepoints?
*Is your study concluded or not?
*Which model best describes the relationship (linear or quadratic?)
*Are there outliers that could be affecting the fit? (See advanced script)

## 3 calculate SR score 

We will calculate different SR scores heres to showcase how the SR score is calculated. 

### 3.1 single time points

If you want to calculate SR scores for each assessment you need to base it on the multilevel model. Our assessment revealed, that the linear model best describes the relationship. 

#### 3.1.1 extract intercept and slope

We therefore need to extract the intercept and slope from the multilevel model.

      Task 3.1.1 Save the intercept and slope from the multilevel model (2.1.2) in separate objects. 
      
```{r solution_slope}
intercept_multi  <- EP_multi$coefficients[1]
E_slope_multi  <- EP_multi$coefficients[2]
```

#### 3.1.2 predicted P

We use the extracted intercept and slope to calculate the predicted P based on their E, using a linear equation (y=slope*x+intercept)

The E in the equation needs to be scaled. 

      Task 3.1.2 Calculate the predicted P based on a linear equation, store it as a variable in the dataset
      
```{r solution_predPmulti}
 ds$P_pred_multi<- intercept_multi  + scale(ds$E)*E_slope_multi  
```

#### 3.1.3 SR score

The SR score is then the difference between the actual P and the predicted P, that is the residual of each P to the normative E/P line. 

      Task 3.1.3 Calculate the difference between actual P and predicted P for each participant
      
```{r solution_sr}
 ds$SR<- scale(scale(ds$P) - ds$P_pred_multi)
```

### 3.2 over entire time period

If we want an SR score over the entire time period than we calculate it on the basis on the model in 2.1.1. Our calculations, however, showed that the quadratic model is the best fit (2.2). 

#### 3.2.1 extract intercept and slope
First, we need to extract the intercept and slopes (in a quadratic model there are two slopes)

```{r solution_slopeovertime}
intercept_t1t6  <- EP_quad$coefficients[1]
E_slope_b  <- EP_quad$coefficients[2]
E_slope_a  <- EP_quad$coefficients[3]
```

#### 3.1.2 predicted P

We then calculate the predicted P base on the quadratic equation. (y=slopeA*x^2+slopeB*x+intercept)

      Task 3.1.2 Calculate the predicted P based on a quadratic equation, store it as a variable in the dataset

```{r solution_predpovertime}
 ds$P_t1.t6_pred <- intercept_t1t6  + scale(ds$E_t1.t6)*E_slope_b  + (scale(ds$E_t1.t6)^2)*E_slope_a  
```

#### 3.1.3 SR score

We then again, calculate the difference between actual P and predicted P. 

      Task 3.1.3 Calculate the difference between actual P and predicted P for each participant
      
```{r solution_srt1t6}
 ds$SR_t1.t6<- scale(scale(ds$P_t1.t6) - ds$P_t1.t6_pred)
```


## 4 Why SR? - SR over time

As an illustration as to why the SR score can offer valuable insights into resilience, we will now examine E, P and SR over time. 

      Task 4: Plot E, P and SR over all 6 time points (separate plots for each variable). Then test the difference between time point 1 and time point 6 to see whether E, P and SR change significantly over time. (you could do this within your plot with ggsignif)

```{r solution_sr-over-time}

p_plot <-  ds %>%  
  ggplot(
    aes(
      y = scale(P),
      x = factor(beep),
      fill = beep)
    ) +
  geom_boxplot() +
  ggsignif::geom_signif(comparisons = list(c(1,6)), 
                        test =  t.test, 
                        map_signif_level = TRUE,
                        step_increase = 0.055, 
                        vjust = 0.4) +
  xlab("time points")+
  ylab("Mental health symptoms (GHQ-12)") +
  theme(legend.position = "none",
        axis.title = element_text(size = 15))

e_plot <-  ds %>%  
  ggplot(
    aes(
      y = scale(E),
      x = factor(beep),
      fill = beep)
    ) +
  geom_boxplot() +
  ggsignif::geom_signif(comparisons = list(c(1,6)), 
                        test =  t.test, 
                        map_signif_level = TRUE,
                        step_increase = 0.055, 
                        vjust = 0.4) +
  xlab("time points")+
  ylab("Stressor exposure (E)") +
  theme(legend.position = "none",
        axis.title = element_text(size = 15))

sr_plot <-  ds %>%  
  ggplot(
    aes(
      y = SR,
      x = factor(beep),
      fill = beep)
    ) +
  geom_boxplot() +
  ggsignif::geom_signif(comparisons = list(c(1,6)), 
                        test =  t.test, 
                        map_signif_level = TRUE,
                        step_increase = 0.055, 
                        vjust = 0.4) +
  xlab("time points")+
  ylab("Stressor reactivity (SR)") +
  theme(legend.position = "none",
        axis.title = element_text(size = 15))

p_plot
e_plot
sr_plot

ggpubr::ggarrange(p_plot, e_plot, sr_plot, nrow = 1)
```

We can see that the change and E and P are significant, but SR is not. Likely the changes in P are explained by changes in E, by controlling for E we can disentangle the causes of these changes.


